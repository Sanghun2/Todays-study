{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 강화학습&딥러닝을 들어가며.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 강화학습&딥러닝\n",
    "\n",
    "1주차 - 단층 퍼셉트론(텐서 연산/ 미니 배치/ 경사하강법)\n",
    "2주차 - 다층 퍼셉트론(다양한 하이퍼 파라미터 수정 실험)\n",
    "3주차 - 합성곱 신경망(이미지 처리를 위한 기본 개념 및 전이학습)\n",
    "4주차 - 순환 신경망(순환신경망과 LSTM을 활용한 문제 해결)\n",
    "5주차 - 생성적 적대 신경망(GAN의 구조 탐색 및 구축)\n",
    "6주차  - 강화학습(OPEN AI Gym & 유니티)\n",
    "\n",
    "월화 - 개념\n",
    "수목 - 실습\n",
    "\n",
    "### 단층퍼셉트론(SLP,single layer perceptron)\n",
    "퍼셉트론은 수많은 가중치와 연결되어 있다.  \n",
    "퍼셉트론끼리는 영향을 줄 수 없다.  \n",
    "퍼셉트론은 독립적인 정보를 생산  \n",
    "가중치와 편향은 대표적인 파라미터  \n",
    "문제풀이에 적합한 파라미터의 조화  \n",
    "파라미터와 하이퍼파라미터는 다르다.  \n",
    "최종적으로 출력하는 계층을 출력계층이라고 한다.\n",
    "고급 신경망 구조의 기본요소\n",
    "\n",
    "<1.2 텐서연산과 미니배치의 활용>\n",
    "텐서 : 다차원 숫자의 배열(1차원 벡터, 0차원도 텐서)\n",
    "선형연산 : 일차식으로 표현되는 과정\n",
    "비선형 연산: 일차식으로 나타낼 수 없는 연산\n",
    "  \n",
    "하이퍼 파라미터  \n",
    "에폭 수나 미니배치 크기처럼 학습과정에서 변경되지 않으면소 신경망 구조나 학습 결과에 영향을 미치는 요인\n",
    "\n",
    "에폭  \n",
    "학습데이터 전체에 대한 한 차례 처리\n",
    "\n",
    "미니배치(minibatch)  \n",
    "신경망이 여러 데이터를 한꺼번에 처리하는 것  \n",
    "데이터처리의 효율을 높이면서 개별 특성에 너무 치우치지 않도록 해준다.  \n",
    "\n",
    "\n",
    "> ##### 회귀분석\n",
    ">> 여러가지 답을 한다.\n",
    "\n",
    "> ##### 이진판단\n",
    ">> 둘 중 하나의 선택을 한다.\n",
    "\n",
    "> ##### 선택분류\n",
    ">> 여러가지 선택지 중 하나를 선택한다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 마치며.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
